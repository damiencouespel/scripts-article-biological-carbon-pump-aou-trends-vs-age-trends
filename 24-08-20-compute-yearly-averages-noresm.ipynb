{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "865b06ff-42ba-43f1-8d5a-4d893be33ad5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4df06642-bc54-44b7-84fb-f9e1a19d2d11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 283 ms, sys: 69.2 ms, total: 352 ms\n",
      "Wall time: 1.55 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<xarray.core.options.set_options at 0x7f7e44f13670>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "%load_ext memory_profiler\n",
    "\n",
    "import datetime\n",
    "import os, glob, sys, gc\n",
    "import warnings\n",
    "# warnings.filterwarnings('ignore', '.*invalid value encountered in true_divide.*', )\n",
    "\n",
    "from dask.diagnostics import ProgressBar\n",
    "pbar = ProgressBar(minimum=10)\n",
    "pbar.register()\n",
    "#pbar.unregister()\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "xr.set_options(keep_attrs=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f58e411-e948-4ed1-9e69-ffdbe2961b2e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Starters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59aad358-2d81-4768-806b-164ce221ac8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-21 16:07:24.689520\n",
      "peak memory: 278.66 MiB, increment: 113.70 MiB\n",
      "CPU times: user 36 ms, sys: 25.5 ms, total: 61.5 ms\n",
      "Wall time: 149 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit -c\n",
    "print(datetime.datetime.now())\n",
    "\n",
    "dirout = '24-08-20-compute-yearly-averages-noresm/'\n",
    "if not os.path.isdir(dirout) : os.mkdir(dirout)\n",
    "\n",
    "netcdfdir = dirout+'netcdf_files/'\n",
    "if not os.path.isdir(netcdfdir) : os.mkdir(netcdfdir)\n",
    "\n",
    "sys.stdout.echo = open(dirout+'stdout.txt', 'w')\n",
    "sys.stderr.echo = open(dirout+'stderr.txt', 'w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407a4946-6d4d-4945-b20d-57dd9dd74ff7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Main parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d265bef4-c799-4505-8fc6-77c2605829c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-21 16:07:25.019082\n",
      "peak memory: 278.82 MiB, increment: 118.22 MiB\n",
      "CPU times: user 34.3 ms, sys: 10.1 ms, total: 44.4 ms\n",
      "Wall time: 148 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit -c\n",
    "\n",
    "print(datetime.datetime.now())\n",
    "\n",
    "kwopends=dict(use_cftime=True, decode_times=None,\n",
    "              decode_cf=True, decode_coords=True)\n",
    "kwopenmfds = dict(combine='by_coords', parallel=True, \n",
    "                  use_cftime=True, decode_times=None,\n",
    "                  decode_cf=True, decode_coords=True)\n",
    "\n",
    "\n",
    "rename_dict = {\n",
    "    \"x\": \"i\",\n",
    "    \"y\": \"j\",\n",
    "    \"lat\": \"latitude\", \n",
    "    \"lon\": \"longitude\",\n",
    "    \"nav_lat\": \"latitude\", \n",
    "    \"nav_lon\": \"longitude\",\n",
    "    'lev': 'depth', \n",
    "    'deptht': 'depth', \n",
    "    'olevel': 'depth', \n",
    "    \"Depth\":\"depth\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1862e0d6-9122-447b-92c1-471146307c22",
   "metadata": {},
   "source": [
    "# Define some functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e936ac1-9b97-407a-963d-aed0406c6f53",
   "metadata": {},
   "source": [
    "## Preparation of data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bace985d-2f71-4524-a3f3-bc7695b2d1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_180_lon(zwda, verbose=False): \n",
    "    if verbose: print(\"func: shift_180_lon\")\n",
    "    \n",
    "    try: \n",
    "        if not np.nanmin(zwda['longitude']) < -150: \n",
    "            zwda['longitude'] = (zwda['longitude'] + 180) % 360 - 180\n",
    "            addtxt=str(datetime.datetime.now())+' shift_180_lon to get longitude from -180 to 180'\n",
    "            try: zwda.attrs['history'] =  addtxt + ' ; '+zwda.attrs['history']\n",
    "            except: zwda.attrs['history'] =  addtxt             \n",
    "        #\n",
    "    except: print('WARNING! longitude likely not shifted')\n",
    "    return zwda\n",
    "#\n",
    "\n",
    "def rename_vars_dims_coords(ds, rename_dict, verbose=False):\n",
    "    \"\"\"\n",
    "    Renames variables, dimensions, and coordinates in an xarray Dataset according to the provided rename dictionary.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    ds : xr.Dataset\n",
    "        The xarray Dataset to be renamed.\n",
    "    rename_dict : Dict[str, str]\n",
    "        Dictionary containing the variable, dimension, or coordinate names to be renamed. \n",
    "        The keys represent the original names, and the values represent the new names.\n",
    "    verbose : bool, optional\n",
    "        If True, prints the function name at the start and end of execution (default is False).\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    xr.Dataset\n",
    "        A new xarray Dataset with variables, dimensions, and coordinates renamed according to the rename dictionary.\n",
    "    \n",
    "    Example:\n",
    "    --------\n",
    "    import xarray as xr\n",
    "    data = {'temp': ([], [0]), 'sali': ([], [1])}\n",
    "    coords = {'time': [0]}\n",
    "    ds = xr.Dataset(data, coords)\n",
    "    renamed_ds = rename_vars_dims_coords(ds, {'temp': 'temperature', 'sali': 'salinity'})\n",
    "\n",
    "    Dependencies:\n",
    "    -------------\n",
    "    xarray\n",
    "    \"\"\"\n",
    "    if verbose: print('func: rename_vars_dims_coords')\n",
    "    for old_name, new_name in rename_dict.items():\n",
    "        if (old_name in ds.variables) | (old_name in ds.dims) | (old_name in ds.coords): \n",
    "            ds = ds.rename({old_name: new_name})\n",
    "        #\n",
    "    if verbose: print('endfunc')\n",
    "    return ds\n",
    "#\n",
    "\n",
    "def split_coords_dimensions(ds, verbose=False):\n",
    "    \"\"\"\n",
    "    Splits the latitude, longitude, and depth dimensions and coordinates of an xarray dataset into separate variables,\n",
    "    updates their names, and assigns them back to the dataset.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    ds : xr.Dataset\n",
    "        The xarray Dataset to be updated.\n",
    "    verbose : bool, optional\n",
    "        If True, prints the function name at the start and end of execution (default is False).\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    xr.Dataset\n",
    "        A new xarray Dataset with the latitude, longitude, and depth dimensions and coordinates split into separate variables\n",
    "        and reassigned to the original dataset.\n",
    "    \n",
    "    Example:\n",
    "    --------\n",
    "    import xarray as xr\n",
    "    data = {'temp': ([0, 1, 2], [0, 1]), 'sali': ([0, 1, 2], [0, 1])}\n",
    "    coords = {'latitude': [0, 1, 2], 'longitude': [0, 1], 'depth': [0, 1, 2]}\n",
    "    ds = xr.Dataset(data, coords)\n",
    "    updated_ds = split_coords_dimensions(ds)\n",
    "\n",
    "    Dependencies:\n",
    "    -------------\n",
    "    xarray\n",
    "    \"\"\"\n",
    "    if verbose: print('func: split_coords_dimensions')\n",
    "    new_coords = {}\n",
    "    new_coords2 = {}\n",
    "    new_dims = {}\n",
    "    dim_name_dict = dict(latitude='j', longitude='i', depth='k')\n",
    "    dimschanged = []\n",
    "    for name, coord in ds.coords.items():\n",
    "        if name in ds.dims and name in [\"latitude\", \"longitude\", \"depth\"]:\n",
    "            new_coords[name + \"_coord\"] = coord\n",
    "            new_dims[name] = dim_name_dict[name]\n",
    "            new_coords2[name + \"_coord\"] = name\n",
    "            dimschanged.append(name)\n",
    "    if verbose: print('endfunc')\n",
    "    for name in ['k', 'j', 'i']: \n",
    "        if name in ds.coords: dimschanged.append(name)\n",
    "    #\n",
    "    return ds.assign_coords(new_coords).rename_dims(new_dims).drop_vars(dimschanged).rename(new_coords2)\n",
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88eeb6db-1b12-49e4-beec-dfeecf083b3c",
   "metadata": {},
   "source": [
    "## Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e396ffee-396f-4f7c-9e02-7cccdd0c1c5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_esgf_dataset_filepaths(variable, sourceID, experimentID, \n",
    "                               freq='mon', grid='g*', version='latest', \n",
    "                               variant='r1i1p1f1',\n",
    "                               mipera = 'CMIP6', diresgf='/mnt/reef-ns1002k-esgf/', verbose=False, **kwargs): \n",
    "    \"\"\"\n",
    "    Returns the filepaths of the remote netCDF files corresponding to the specified dataset of the Earth System\n",
    "    Grid Federation (ESGF) data portal on NIRD.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    variable : str\n",
    "        Variable to search for on ESGF data portal.\n",
    "    sourceID : str\n",
    "        Name of the data source on the ESGF data portal.\n",
    "    experimentID : str\n",
    "        Name of the experiment on the ESGF data portal.\n",
    "    freq : str, optional\n",
    "        Frequency of the data (default is 'mon').\n",
    "    grid : str, optional\n",
    "        Type of grid (default is 'g*').\n",
    "    version : str, optional\n",
    "        Version of the data being queried (default is 'latest').\n",
    "    variant : str, optional\n",
    "        Label for the variant of the data being queried (default is 'r1i1p1f1').\n",
    "    mipera : str, optional\n",
    "        Name of the CMIP era being queried (default is 'CMIP6').\n",
    "    diresgf : str, optional\n",
    "        Absolute path to the directory where the data is stored (default is '/mnt/reef-ns1002k-esgf/').\n",
    "    verbose : bool, optional\n",
    "        If True, prints the function name at the start and end of execution (default is False).\n",
    "    **kwargs : dict, optional\n",
    "        Other key-value arguments to be passed in the function.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    List[str]\n",
    "        A list of filepaths corresponding to the specified dataset on the ESGF data portal.\n",
    "\n",
    "    Example:\n",
    "    --------\n",
    "    fp_list = get_esgf_dataset_filepaths('tas', 'CanESM5', 'historical', freq='mon')\n",
    "\n",
    "    Dependencies:\n",
    "    -------------\n",
    "    glob, sys\n",
    "    \"\"\"\n",
    "    import glob, sys\n",
    "    \n",
    "    if verbose: print('func: get_esgf_dataset_filepaths')\n",
    "    \n",
    "    if experimentID in ['1pctCO2', 'piControl', 'historical', 'abrupt-4xCO2']: zwActivity='CMIP'\n",
    "    elif experimentID in ['ssp126', 'ssp245', 'ssp585']: zwActivity='ScenarioMIP'\n",
    "    else: sys.exit('Check experimentID, case not implemented')\n",
    "    \n",
    "    if sourceID in ['CESM2', 'CESM2-WACCM']: zwInstitutionID = 'NCAR'\n",
    "    elif sourceID in ['ACCESS-ESM1-5']: zwInstitutionID = 'CSIRO'\n",
    "    elif sourceID in ['CNRM-ESM2-1']: zwInstitutionID = 'CNRM-CERFACS'\n",
    "    elif sourceID in ['CanESM5', 'CanESM5-CanOE']: zwInstitutionID = 'CCCma'\n",
    "    elif sourceID in ['UKESM1-0-LL']: zwInstitutionID = 'NIMS-KMA'\n",
    "    elif sourceID in ['GFDL-CM4', 'GFDL-ESM4']: zwInstitutionID = 'NOAA-GFDL'\n",
    "    elif sourceID in ['IPSL-CM6A-LR', 'IPSL-CM6A-LR-INCA']: zwInstitutionID = 'IPSL'\n",
    "    elif sourceID in ['MIROC-ES2L']: zwInstitutionID = 'MIROC'\n",
    "    elif sourceID in ['MPI-ESM1-2-LR', 'ICON-ESM-LR']: zwInstitutionID = 'MPI-M'\n",
    "    elif sourceID in ['NorESM2-LM']: zwInstitutionID = 'NCC'\n",
    "    else: sys.exit('Check sourceID, case not implemented')\n",
    "    \n",
    "    ocean_list = ['fgco2', 'intpp', 'o2', 'thetao', 'so', 'agessc', 'po4', 'no3', 'dissic', 'talk']\n",
    "    if variable in ocean_list: zwTableID = 'O'+freq\n",
    "    elif variable in ['areacello']: zwTableID='Ofx'\n",
    "    elif variable in ['psl']: zwTableID='A'+freq\n",
    "    else: sys.exit('!!! WARNING !!! Check variable, case not implemented')\n",
    "        \n",
    "    zwdname = diresgf + mipera +'/'+ zwActivity +'/'+ \\\n",
    "        zwInstitutionID +'/'+ sourceID +'/'+ \\\n",
    "        experimentID  +'/'+ variant +'/'+ zwTableID +'/'+ \\\n",
    "        variable+'/'+ grid +'/'+ version +'/'\n",
    "    zwfname = variable +'_'+ zwTableID +'_'+ sourceID +'_'+ \\\n",
    "        experimentID +'_'+ variant +'_'+ grid +'*.nc' \n",
    "\n",
    "    if verbose: print('endfunc')\n",
    "    return glob.glob(zwdname + zwfname)\n",
    "#\n",
    "def nan_helper(y):\n",
    "    \"\"\"Helper to handle indices and logical indices of NaNs.\n",
    "\n",
    "    Input:\n",
    "        - y, 1d numpy array with possible NaNs\n",
    "    Output:\n",
    "        - nans, logical indices of NaNs\n",
    "        - index, a function, with signature indices= index(logical_indices),\n",
    "          to convert logical indices of NaNs to 'equivalent' indices\n",
    "    Example:\n",
    "        >>> # linear interpolation of NaNs\n",
    "        >>> nans, x= nan_helper(y)\n",
    "        >>> y[nans]= np.interp(x(nans), x(~nans), y[~nans])\n",
    "        nb: y[~nans] values of y that are not nans\n",
    "            x(~nans) indexes of y that are not nans\n",
    "    \"\"\"\n",
    "\n",
    "    return np.isnan(y), lambda z: z.nonzero()[0]\n",
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d3d6d4-17d2-4fa7-bd45-fb7c23a5972d",
   "metadata": {},
   "source": [
    "# Compute yearly mean for SSP585"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b9fbdc-2311-43ed-b47e-66b96747c966",
   "metadata": {},
   "source": [
    "## Check data avaibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41175424-2716-4696-b1ec-881c200dae31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-21 16:08:57.850687\n",
      "# Compute yearly mean for SSP585\n",
      "## Check data avaibility\n",
      "============\n",
      "O2\n",
      "============\n",
      "\n",
      "%s GOOD\n",
      "2015 to 2100, 86.0 years (1032 months)\n",
      "------------\n",
      "\n",
      "============\n",
      "THETAO\n",
      "============\n",
      "\n",
      "%s GOOD\n",
      "2015 to 2100, 86.0 years (1032 months)\n",
      "------------\n",
      "\n",
      "============\n",
      "SO\n",
      "============\n",
      "\n",
      "%s GOOD\n",
      "2015 to 2100, 86.0 years (1032 months)\n",
      "------------\n",
      "\n",
      "============\n",
      "AGESSC\n",
      "============\n",
      "\n",
      "%s GOOD\n",
      "2015 to 2100, 86.0 years (1032 months)\n",
      "------------\n",
      "\n",
      "============\n",
      "DISSIC\n",
      "============\n",
      "\n",
      "%s GOOD\n",
      "2015 to 2100, 86.0 years (1032 months)\n",
      "------------\n",
      "\n",
      "============\n",
      "TALK\n",
      "============\n",
      "\n",
      "%s GOOD\n",
      "2015 to 2100, 86.0 years (1032 months)\n",
      "------------\n",
      "\n",
      "============\n",
      "PO4\n",
      "============\n",
      "\n",
      "%s GOOD\n",
      "2015 to 2100, 86.0 years (1032 months)\n",
      "------------\n",
      "\n",
      "peak memory: 585.15 MiB, increment: 400.53 MiB\n",
      "CPU times: user 2.35 s, sys: 1.19 s, total: 3.54 s\n",
      "Wall time: 19.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit -c\n",
    "print(datetime.datetime.now())\n",
    "print('# Compute yearly mean for SSP585')\n",
    "print('## Check data avaibility')\n",
    "\n",
    "simu = 'ssp585'\n",
    "esm  = 'NorESM2-LM' \n",
    "\n",
    "var_list = ['o2', 'thetao', 'so', 'agessc', 'dissic', 'talk', 'po4']\n",
    "for var in var_list:\n",
    "    \n",
    "    print('============')\n",
    "    print(var.upper())\n",
    "    print('============')\n",
    "    print('')\n",
    "\n",
    "    # Load data\n",
    "    fname_list = get_esgf_dataset_filepaths(var, esm, simu, \n",
    "                                            diresgf='/mnt/reef-ns1002k-ns9034k/', \n",
    "                                            version='v20191108', \n",
    "                                            variant='r1i1p1f1', grid='gr')\n",
    "    zwds = xr.open_mfdataset(fname_list, **kwopenmfds)\n",
    "    ymin = int(np.min(zwds['time.year']))\n",
    "    ymax = int(np.max(zwds['time.year']))\n",
    "    tstep = zwds[var].shape[0]\n",
    "    good = tstep/12 == ymax-ymin+1\n",
    "    if good: \n",
    "        print('GOOD')\n",
    "        print(f'{ymin} to {ymax}, {tstep/12} years ({tstep} months)')\n",
    "        print('------------')\n",
    "    else:\n",
    "        print('!!! WARNING some year are missing, \\\n",
    "        here is the list of available files: ')\n",
    "        for fname in fname_list: print(fname)\n",
    "    #\n",
    "    print('')\n",
    "    #\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27c7427-1faf-4623-8740-cb8b1f7af1c3",
   "metadata": {},
   "source": [
    "## Compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26c82317-ec5d-441d-aa2b-e095b400cfc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-21 16:16:41.939714\n",
      "# Compute yearly mean for SSP585\n",
      "## Compute\n",
      "Computing yearly mean for o2...\n",
      "Done with o2\n",
      "Computing yearly mean for thetao...\n",
      "Done with thetao\n",
      "Computing yearly mean for so...\n",
      "Done with so\n",
      "Computing yearly mean for agessc...\n",
      "Done with agessc\n",
      "Computing yearly mean for dissic...\n",
      "Done with dissic\n",
      "Computing yearly mean for talk...\n",
      "Done with talk\n",
      "Computing yearly mean for po4...\n",
      "Done with po4\n",
      "peak memory: 3019.61 MiB, increment: 2521.24 MiB\n",
      "CPU times: user 20min 36s, sys: 2min 6s, total: 22min 42s\n",
      "Wall time: 24min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit -c\n",
    "print(datetime.datetime.now())\n",
    "print('# Compute yearly mean for SSP585')\n",
    "print('## Compute')\n",
    "\n",
    "\n",
    "simu='ssp585'\n",
    "esm  = 'NorESM2-LM' \n",
    "year_list = ['%04d' %yyy for yyy in np.arange(2015, 2099.5)]\n",
    "\n",
    "var_list = ['o2', 'thetao', 'so', 'agessc', 'dissic', 'talk', 'po4']\n",
    "\n",
    "for var in var_list:\n",
    "\n",
    "    print(f'Computing yearly mean for {var}...')\n",
    "\n",
    "    # Load data\n",
    "    fname_list = get_esgf_dataset_filepaths(var, esm, simu, \n",
    "                                            diresgf='/mnt/reef-ns1002k-ns9034k/', \n",
    "                                            version='v20191108', \n",
    "                                            variant='r1i1p1f1', grid='gr')\n",
    "    zwds = xr.open_mfdataset(fname_list, **kwopenmfds)\n",
    "    zwds2 = zwds[var].to_dataset()\n",
    "    zwds2 = rename_vars_dims_coords(zwds2, rename_dict)\n",
    "    zwds2 = split_coords_dimensions(zwds2)\n",
    "    zwds2 = shift_180_lon(zwds2)\n",
    "\n",
    "    # save for later\n",
    "    zwds_attrs=zwds.attrs\n",
    "    del zwds\n",
    "    gc.collect()\n",
    "\n",
    "    # Loop on years\n",
    "    for year in year_list: \n",
    "\n",
    "        zwda = zwds2.sel(time=year)[var].load()\n",
    "        zwda_tavg = zwda.groupby('time.year').mean(dim='time')\n",
    "        # Clean\n",
    "        del zwda\n",
    "        gc.collect()\n",
    "        # create dataset\n",
    "        zwda_ds = zwda_tavg.to_dataset() \n",
    "        zwda_ds.attrs = zwds_attrs\n",
    "        # Save in netcdf\n",
    "        ncname = netcdfdir+esm+'_'+simu+'_'+var+'_'+year+'.nc'\n",
    "        zwda_ds.to_netcdf(ncname)\n",
    "    #\n",
    "    print(f'Done with {var}')\n",
    "#\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0f30a4-c79d-459c-bb02-9ac950f763b4",
   "metadata": {},
   "source": [
    "# Compute yearly mean for historical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcf5c07-d457-4463-bdec-1e3ee2b35ba6",
   "metadata": {},
   "source": [
    "## Check data avaibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e144ae84-ced0-4e3b-9f8c-eeda942b3c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-21 16:43:18.360385\n",
      "# Compute yearly mean for historical\n",
      "## Check data avaibility\n",
      "============\n",
      "O2\n",
      "============\n",
      "\n",
      "NorESM2-LM GOOD\n",
      "1850 to 2014, 165.0 years (1980 months)\n",
      "------------\n",
      "\n",
      "============\n",
      "THETAO\n",
      "============\n",
      "\n",
      "NorESM2-LM GOOD\n",
      "1850 to 2014, 165.0 years (1980 months)\n",
      "------------\n",
      "\n",
      "============\n",
      "SO\n",
      "============\n",
      "\n",
      "NorESM2-LM GOOD\n",
      "1850 to 2014, 165.0 years (1980 months)\n",
      "------------\n",
      "\n",
      "============\n",
      "AGESSC\n",
      "============\n",
      "\n",
      "NorESM2-LM GOOD\n",
      "1850 to 2014, 165.0 years (1980 months)\n",
      "------------\n",
      "\n",
      "============\n",
      "DISSIC\n",
      "============\n",
      "\n",
      "NorESM2-LM GOOD\n",
      "1850 to 2014, 165.0 years (1980 months)\n",
      "------------\n",
      "\n",
      "============\n",
      "TALK\n",
      "============\n",
      "\n",
      "NorESM2-LM GOOD\n",
      "1850 to 2014, 165.0 years (1980 months)\n",
      "------------\n",
      "\n",
      "============\n",
      "PO4\n",
      "============\n",
      "\n",
      "NorESM2-LM GOOD\n",
      "1850 to 2014, 165.0 years (1980 months)\n",
      "------------\n",
      "\n",
      "peak memory: 2791.36 MiB, increment: 1345.91 MiB\n",
      "CPU times: user 3.3 s, sys: 891 ms, total: 4.19 s\n",
      "Wall time: 31.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit -c\n",
    "print(datetime.datetime.now())\n",
    "print('# Compute yearly mean for historical')\n",
    "print('## Check data avaibility')\n",
    "\n",
    "\n",
    "simu='historical'\n",
    "esm  = 'NorESM2-LM' \n",
    "\n",
    "var_list = ['o2', 'thetao', 'so', 'agessc', 'dissic', 'talk', 'po4']\n",
    "\n",
    "for var in var_list:\n",
    "    \n",
    "    print('============')\n",
    "    print(var.upper())\n",
    "    print('============')\n",
    "    print('')\n",
    "\n",
    "    # Load data\n",
    "    fname_list = get_esgf_dataset_filepaths(var, esm, simu, \n",
    "                                            diresgf='/mnt/reef-ns1002k-ns9034k/', \n",
    "                                            version='v20190815', \n",
    "                                            variant='r1i1p1f1', grid='gr')\n",
    "    zwds = xr.open_mfdataset(fname_list, **kwopenmfds)\n",
    "    ymin = int(np.min(zwds['time.year']))\n",
    "    ymax = int(np.max(zwds['time.year']))\n",
    "    tstep = zwds[var].shape[0]\n",
    "    good = tstep/12 == ymax-ymin+1\n",
    "    if good: \n",
    "        print('%s GOOD'%esm)\n",
    "        print(f'{ymin} to {ymax}, {tstep/12} years ({tstep} months)')\n",
    "        print('------------')\n",
    "    else:\n",
    "        print('!!! WARNING some year are missing, \\\n",
    "        here is the list of available files: ')\n",
    "        for fname in fname_list: print(fname)\n",
    "    #\n",
    "    print('')\n",
    "#\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff1866c-bd84-4a60-a439-5cefa2a102a4",
   "metadata": {},
   "source": [
    "## Compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "99b675f9-80ca-44bd-a10e-8f6191b077e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-21 16:45:17.785117\n",
      "# Compute yearly mean for historical\n",
      "## Compute\n",
      "Computing yearly mean for o2...\n",
      "Done with o2\n",
      "Computing yearly mean for thetao...\n",
      "Done with thetao\n",
      "Computing yearly mean for so...\n",
      "Done with so\n",
      "Computing yearly mean for agessc...\n",
      "Done with agessc\n",
      "Computing yearly mean for dissic...\n",
      "Done with dissic\n",
      "Computing yearly mean for talk...\n",
      "Done with talk\n",
      "Computing yearly mean for po4...\n",
      "Done with po4\n",
      "peak memory: 4431.55 MiB, increment: 3361.83 MiB\n",
      "CPU times: user 40min 10s, sys: 4min 12s, total: 44min 23s\n",
      "Wall time: 47min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit -c\n",
    "print(datetime.datetime.now())\n",
    "print('# Compute yearly mean for historical')\n",
    "print('## Compute')\n",
    "\n",
    "\n",
    "simu='historical'\n",
    "esm  = 'NorESM2-LM' \n",
    "\n",
    "year_list = ['%04d' %yyy for yyy in np.arange(1850, 2014.5)]\n",
    "\n",
    "var_list = ['o2', 'thetao', 'so', 'agessc', 'dissic', 'talk', 'po4']\n",
    "for var in var_list:\n",
    "\n",
    "    print(f'Computing yearly mean for {var}...')\n",
    "\n",
    "    # Load data\n",
    "    fname_list = get_esgf_dataset_filepaths(var, esm, simu, \n",
    "                                            diresgf='/mnt/reef-ns1002k-ns9034k/', \n",
    "                                            version='v20190815', \n",
    "                                            variant='r1i1p1f1', grid='gr')\n",
    "    zwds = xr.open_mfdataset(fname_list, **kwopenmfds)\n",
    "    zwds2 = zwds[var].to_dataset()\n",
    "    zwds2 = rename_vars_dims_coords(zwds2, rename_dict)\n",
    "    zwds2 = split_coords_dimensions(zwds2)\n",
    "    zwds2 = shift_180_lon(zwds2)\n",
    "\n",
    "    # save for later\n",
    "    zwds_attrs=zwds.attrs\n",
    "    del zwds\n",
    "    gc.collect()\n",
    "\n",
    "    # Loop on years\n",
    "    for year in year_list: \n",
    "\n",
    "        zwda = zwds2.sel(time=year)[var].load()\n",
    "        zwda_tavg = zwda.groupby('time.year').mean(dim='time')\n",
    "        # Clean\n",
    "        del zwda\n",
    "        gc.collect()\n",
    "        # create dataset\n",
    "        zwda_ds = zwda_tavg.to_dataset() \n",
    "        zwda_ds.attrs = zwds_attrs\n",
    "        # Save in netcdf\n",
    "        ncname = netcdfdir+esm+'_'+simu+'_'+var+'_'+year+'.nc'\n",
    "        zwda_ds.to_netcdf(ncname)\n",
    "    #\n",
    "    print(f'Done with {var}')\n",
    "#\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638516b0-5022-46c2-984c-e96875b46cfd",
   "metadata": {},
   "source": [
    "# Compute yearly mean for piControl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e396b641-cd8e-45c4-87c7-81e2746147ee",
   "metadata": {},
   "source": [
    "## def shorten_fname_list(fname_list, startyear, endyear):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b4e838f5-11f0-4140-b1e2-2bb4094c02ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def shorten_fname_list(fname_list, startyear, endyear):\n",
    "    fname_list.sort()\n",
    "    new_fname_list = []\n",
    "    for fname in fname_list: \n",
    "        year1_of_fname = int(fname.split('/')[-1].split('_')[-1].split('-')[0][:4])\n",
    "        year2_of_fname = int(fname.split('/')[-1].split('_')[-1].split('-')[1][:4])\n",
    "        startyear_in_between = ((startyear>=year1_of_fname) & (startyear<=year2_of_fname))\n",
    "        endyear_in_between   = ((endyear>=year1_of_fname) & (endyear<=year2_of_fname))\n",
    "        year1_in_between = ((year1_of_fname>=startyear) & (year1_of_fname<=endyear))\n",
    "        year2_in_between = ((year2_of_fname>=startyear) & (year2_of_fname<=endyear))\n",
    "        if startyear_in_between | endyear_in_between | year1_in_between | year2_in_between: \n",
    "            if not (fname in new_fname_list): \n",
    "                new_fname_list.append(fname)\n",
    "        #\n",
    "    #\n",
    "    #\n",
    "    # if len(new_fname_list)==0: \n",
    "    #     zwmax = int(fname_list[-1][-9:-5])\n",
    "    #     zwmin = zwmax-99\n",
    "    #     for fname in fname_list: \n",
    "    #         year1_of_fname = fname.split('/')[-1].split('_')[-1].split('-')[0][:4]\n",
    "    #         for search in np.arange(zwmin, zwmax): \n",
    "    #             if '%04d'%search==year1_of_fname:\n",
    "    #                 if not (fname in new_fname_list): new_fname_list.append(fname)\n",
    "    #                 #\n",
    "    #             #\n",
    "    #         #\n",
    "    #     #\n",
    "    # #\n",
    "    if len(new_fname_list)==0: new_fname_list=fname_list\n",
    "    return new_fname_list\n",
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5398af8-4e89-40ef-a925-17cb8a4cdb5b",
   "metadata": {},
   "source": [
    "## Check data avaibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "74fe6c22-09cd-4fca-8a8d-912b209f1da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-21 16:44:20.993939\n",
      "# Compute yearly mean for piControl\n",
      "## Check data avaibility\n",
      "============\n",
      "O2\n",
      "============\n",
      "\n",
      "piControl targeted time period: 1600-1849\n",
      "NorESM2-LM GOOD, time period complete and match target\n",
      "1600 to 1850, 251.0 years (3012 months)\n",
      "------------\n",
      "\n",
      "============\n",
      "THETAO\n",
      "============\n",
      "\n",
      "piControl targeted time period: 1600-1849\n",
      "NorESM2-LM GOOD, time period complete and match target\n",
      "1600 to 1850, 251.0 years (3012 months)\n",
      "------------\n",
      "\n",
      "============\n",
      "SO\n",
      "============\n",
      "\n",
      "piControl targeted time period: 1600-1849\n",
      "NorESM2-LM GOOD, time period complete and match target\n",
      "1600 to 1850, 251.0 years (3012 months)\n",
      "------------\n",
      "\n",
      "============\n",
      "AGESSC\n",
      "============\n",
      "\n",
      "piControl targeted time period: 1600-1849\n",
      "NorESM2-LM GOOD, time period complete and match target\n",
      "1600 to 1850, 251.0 years (3012 months)\n",
      "------------\n",
      "\n",
      "============\n",
      "DISSIC\n",
      "============\n",
      "\n",
      "piControl targeted time period: 1600-1849\n",
      "NorESM2-LM GOOD, time period complete and match target\n",
      "1600 to 1850, 251.0 years (3012 months)\n",
      "------------\n",
      "\n",
      "============\n",
      "TALK\n",
      "============\n",
      "\n",
      "piControl targeted time period: 1600-1849\n",
      "NorESM2-LM GOOD, time period complete and match target\n",
      "1600 to 1850, 251.0 years (3012 months)\n",
      "------------\n",
      "\n",
      "============\n",
      "PO4\n",
      "============\n",
      "\n",
      "piControl targeted time period: 1600-1849\n",
      "NorESM2-LM GOOD, time period complete and match target\n",
      "1600 to 1850, 251.0 years (3012 months)\n",
      "------------\n",
      "\n",
      "peak memory: 2008.35 MiB, increment: 1003.24 MiB\n",
      "CPU times: user 5.48 s, sys: 1.48 s, total: 6.96 s\n",
      "Wall time: 49.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit -c\n",
    "print(datetime.datetime.now())\n",
    "print('# Compute yearly mean for piControl')\n",
    "print('## Check data avaibility')\n",
    "\n",
    "refyear_dict = {\n",
    "    'MPI-ESM1-2-LR': 1850,\n",
    "    'ACCESS-ESM1-5':  161,\n",
    "    'IPSL-CM6A-LR' : 1910,\n",
    "    'CanESM5'      : 5201,\n",
    "    'MIROC-ES2L'   : 1850,\n",
    "    'NorESM2-LM'   : 1600\n",
    "}\n",
    "\n",
    "simu='piControl'\n",
    "esm  = 'NorESM2-LM' \n",
    "\n",
    "var_list = ['o2', 'thetao', 'so', 'agessc', 'dissic', 'talk', 'po4']\n",
    "\n",
    "for var in var_list:\n",
    "    \n",
    "    print('============')\n",
    "    print(var.upper())\n",
    "    print('============')\n",
    "    print('')\n",
    "\n",
    "\n",
    "    # startyear, endyear = refyear_dict[esm], refyear_dict[esm]+164\n",
    "    startyear, endyear = refyear_dict[esm], refyear_dict[esm]+165+84\n",
    "    print('piControl targeted time period: %04d-%04d'%(startyear, endyear))\n",
    "\n",
    "    # Load data\n",
    "    fname_list = get_esgf_dataset_filepaths(var, esm, simu, \n",
    "                                            diresgf='/mnt/reef-ns1002k-ns9034k/', \n",
    "                                            version='v20210118', \n",
    "                                            variant='r1i1p1f1', grid='gr')\n",
    "    new_fname_list = shorten_fname_list(fname_list, startyear, endyear)\n",
    "    zwds = xr.open_mfdataset(new_fname_list, **kwopenmfds)\n",
    "    ymin = int(np.min(zwds['time.year']))\n",
    "    ymax = int(np.max(zwds['time.year']))\n",
    "    tstep = zwds[var].shape[0]\n",
    "    good1 = tstep/12 == ymax-ymin+1\n",
    "    good2 = (startyear>=ymin) & (endyear<=ymax)\n",
    "    if good1 & good2: \n",
    "        print('%s GOOD, time period complete and match target'%esm)\n",
    "        print(f'{ymin} to {ymax}, {tstep/12} years ({tstep} months)')\n",
    "    elif good1 and (not good2): \n",
    "        print('!!! WARNING !!! %s, time period complete BUT do not match target'%esm)\n",
    "        print(f'{ymin} to {ymax}, {tstep/12} years ({tstep} months), \\\n",
    "        here is the list of the files:')\n",
    "        for fname in new_fname_list: print(fname)\n",
    "    else: \n",
    "        print('!!! WARNING !!! %s, some years are missing, \\\n",
    "        here is the list of available files: '%esm)\n",
    "        for fname in new_fname_list: print(fname)\n",
    "    #\n",
    "    print('------------')\n",
    "    print('')\n",
    "#\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1320e0-123d-479d-8195-4fdaae52026d",
   "metadata": {},
   "source": [
    "## Compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b211b776-91f9-48cb-84e9-6e1d996d6dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-21 17:32:26.042909\n",
      "# Compute yearly mean for piControl\n",
      "## Compute\n",
      "Computing yearly mean for o2...\n",
      "Done with o2\n",
      "Computing yearly mean for thetao...\n",
      "Done with thetao\n",
      "Computing yearly mean for so...\n",
      "Done with so\n",
      "Computing yearly mean for agessc...\n",
      "Done with agessc\n",
      "Computing yearly mean for dissic...\n",
      "Done with dissic\n",
      "Computing yearly mean for talk...\n",
      "Done with talk\n",
      "Computing yearly mean for po4...\n",
      "Done with po4\n",
      "peak memory: 6125.88 MiB, increment: 3866.18 MiB\n",
      "CPU times: user 1h 52s, sys: 6min 16s, total: 1h 7min 8s\n",
      "Wall time: 1h 11min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit -c\n",
    "print(datetime.datetime.now())\n",
    "print('# Compute yearly mean for piControl')\n",
    "print('## Compute')\n",
    "\n",
    "refyear_dict = {\n",
    "    'MPI-ESM1-2-LR': 1850,\n",
    "    'ACCESS-ESM1-5':  161,\n",
    "    'IPSL-CM6A-LR' : 1910,\n",
    "    'CanESM5'      : 5201,\n",
    "    'MIROC-ES2L'   : 1850,\n",
    "    'NorESM2-LM'   : 1600\n",
    "}\n",
    "\n",
    "simu='piControl'\n",
    "esm  = 'NorESM2-LM' \n",
    "\n",
    "var_list = ['o2', 'thetao', 'so', 'agessc', 'dissic', 'talk', 'po4']\n",
    "\n",
    "for var in var_list:\n",
    "\n",
    "    print(f'Computing yearly mean for {var}...')\n",
    "\n",
    "    # startyear, endyear = refyear_dict[esm], refyear_dict[esm]+164\n",
    "    startyear, endyear = refyear_dict[esm], refyear_dict[esm]+165+84\n",
    "\n",
    "    # Load data\n",
    "    fname_list = get_esgf_dataset_filepaths(var, esm, simu, \n",
    "                                            diresgf='/mnt/reef-ns1002k-ns9034k/', \n",
    "                                            version='v20210118', \n",
    "                                            variant='r1i1p1f1', grid='gr')\n",
    "    new_fname_list = shorten_fname_list(fname_list, startyear, endyear)\n",
    "    zwds = xr.open_mfdataset(new_fname_list, **kwopenmfds)\n",
    "\n",
    "    zwds2 = zwds[var].to_dataset()\n",
    "    zwds2 = rename_vars_dims_coords(zwds2, rename_dict)\n",
    "    zwds2 = split_coords_dimensions(zwds2)\n",
    "    zwds2 = shift_180_lon(zwds2)\n",
    "\n",
    "    # save for later\n",
    "    zwds_attrs=zwds.attrs\n",
    "    year_list = ['%04d' %yyy for yyy in np.arange(startyear, endyear+.5)]\n",
    "    del zwds\n",
    "    gc.collect()\n",
    "\n",
    "    # Loop on years\n",
    "    for year in year_list: \n",
    "\n",
    "        zwda = zwds2.sel(time=year)[var].load()\n",
    "        zwda_tavg = zwda.groupby('time.year').mean(dim='time')\n",
    "        # Clean\n",
    "        del zwda\n",
    "        gc.collect()\n",
    "        # create dataset\n",
    "        zwda_ds = zwda_tavg.to_dataset() \n",
    "        zwda_ds.attrs = zwds_attrs\n",
    "        # Save in netcdf\n",
    "        ncname = netcdfdir+esm+'_'+simu+'_'+var+'_'+year+'.nc'\n",
    "        zwda_ds.to_netcdf(ncname)\n",
    "    #\n",
    "    print(f'Done with {var}')\n",
    "#\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61564e9a-b357-44f4-9050-f5613be0d87b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
