{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59d65aa7-18a9-44ed-9c4f-7e766942864c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bd78ca5-4317-47d9-b888-0ea0b52a81ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.03 s, sys: 1.32 s, total: 2.35 s\n",
      "Wall time: 1.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%load_ext memory_profiler\n",
    "\n",
    "import datetime\n",
    "import os, glob, sys, gc\n",
    "import warnings\n",
    "# warnings.filterwarnings('ignore', '.*invalid value encountered in true_divide.*', )\n",
    "\n",
    "from dask.diagnostics import ProgressBar\n",
    "pbar = ProgressBar(minimum=10)\n",
    "pbar.register()\n",
    "#pbar.unregister()\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "xr.set_options(keep_attrs=True)\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "import cartopy.crs       as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy\n",
    "\n",
    "import cmcrameri\n",
    "\n",
    "mpl.rcParams['savefig.dpi'] = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836aa65f-6654-41e3-a786-41e5127a2fc4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Starters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37e7c392-be53-43b6-97b4-a8110e224dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-22 16:35:30.019427\n",
      "peak memory: 316.14 MiB, increment: 124.60 MiB\n",
      "CPU times: user 51.3 ms, sys: 20.9 ms, total: 72.2 ms\n",
      "Wall time: 158 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit -c\n",
    "print(datetime.datetime.now())\n",
    "\n",
    "from IPython.core.magic import register_cell_magic\n",
    "import traceback\n",
    "\n",
    "dirout = '24-08-22-compute-aou-noresm/'\n",
    "if not os.path.isdir(dirout) : os.mkdir(dirout)\n",
    "\n",
    "netcdfdir = dirout+'netcdf_files/'\n",
    "if not os.path.isdir(netcdfdir) : os.mkdir(netcdfdir)\n",
    "\n",
    "sys.stdout.echo = open(dirout+'stdout.txt', 'w')\n",
    "sys.stderr.echo = open(dirout+'stderr.txt', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eabcdfb0-832a-479a-8547-b14242eac184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-22 16:32:28.840452\n",
      "peak memory: 385.30 MiB, increment: 167.43 MiB\n",
      "CPU times: user 94 ms, sys: 13.8 ms, total: 108 ms\n",
      "Wall time: 215 ms\n"
     ]
    }
   ],
   "source": [
    "# #-------------------\n",
    "# # Save errors and outputs in files\n",
    "# #-------------------\n",
    "# \n",
    "# sys.stdout.echo = open(dirout+'stdout.txt', 'w')\n",
    "# # sys.stderr.echo = open(dirout+'stderr.txt', 'w')\n",
    "# \n",
    "# # Create error.log and erase former one\n",
    "# error_file = dirout+'error.log'\n",
    "# fff = open(error_file, 'w')\n",
    "# fff.close()\n",
    "# \n",
    "# @register_cell_magic\n",
    "# def capture_errors(line, cell):\n",
    "#     # Get the file path from the magic line arguments\n",
    "#     # file_path = dirout+line.strip()\n",
    "#     file_path = error_file\n",
    "#     ip = get_ipython()\n",
    "#     try:\n",
    "#         # Split the cell content by lines and detect magic commands\n",
    "#         cell_lines = cell.strip().split('\\n')\n",
    "#         magic_lines = [line for line in cell_lines if line.startswith('%%')]\n",
    "#         \n",
    "#         # Execute each magic command in the cell\n",
    "#         ilines = 0\n",
    "#         for magic_line in magic_lines:\n",
    "#             magic_command = magic_line.split()[0][2:]  # Extract the magic command\n",
    "#             magic_param = ' '.join(magic_line.split()[1:])\n",
    "#             ip.run_line_magic(magic_command, magic_param)\n",
    "#             ilines += 1\n",
    "#         #\n",
    "#         cell_code = \"\\n\".join(cell_lines[ilines:])  # Get the code below the magic command line     \n",
    "#         # Execute the cell code\n",
    "#         exec(cell_code, globals(), locals())\n",
    "#     except Exception as e:\n",
    "#         error_message = traceback.format_exc()\n",
    "#         # Capture any exceptions and write the traceback to the file in append mode\n",
    "#         with open(file_path, \"a\") as f:\n",
    "#             f.write(error_message)\n",
    "#             f.write(\"\\n\")  # Add a new line after each error entry\n",
    "#         # Print the error message to the notebook\n",
    "#         print(f\"An error occurred:\\n{error_message}\")\n",
    "#         print(f\"The error was also written to {file_path}\")\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35015c65-5a5d-415c-b779-6add1f0b8bbc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Main parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83df7a10-5b16-4376-88d6-dcc0bb53f164",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-22 16:35:39.852423\n",
      "{'use_cftime': True, 'decode_times': None, 'decode_cf': True, 'decode_coords': True}\n",
      "peak memory: 316.59 MiB, increment: 133.04 MiB\n",
      "CPU times: user 38.9 ms, sys: 12.8 ms, total: 51.7 ms\n",
      "Wall time: 156 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit -c\n",
    "print(datetime.datetime.now())\n",
    "\n",
    "kwopends = dict(use_cftime=True, decode_times=None,\n",
    "                decode_cf=True, decode_coords=True)\n",
    "\n",
    "kwopenmfds = dict(combine='by_coords', parallel=True, \n",
    "                  use_cftime=True, decode_times=None,\n",
    "                  decode_cf=True, decode_coords=True)\n",
    "\n",
    "rename_dict = {\n",
    "    \"x\": \"i\",\n",
    "    \"y\": \"j\",\n",
    "    \"lat\": \"latitude\", \n",
    "    \"lon\": \"longitude\",\n",
    "    \"nav_lat\": \"latitude\", \n",
    "    \"nav_lon\": \"longitude\",\n",
    "    'lev': 'depth', \n",
    "    'deptht': 'depth', \n",
    "    'olevel': 'depth', \n",
    "    \"Depth\":\"depth\"\n",
    "}\n",
    "\n",
    "print(kwopends)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82c5382-a5a6-4a44-ad13-9b62f2590abc",
   "metadata": {},
   "source": [
    "# Define some functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70dbd91-26d4-44db-bc44-928e937fdbac",
   "metadata": {},
   "source": [
    "## Preparation of data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60d1372a-949b-4afc-ba29-9f23b3550a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_180_lon(zwda, verbose=False): \n",
    "    if verbose: print(\"func: shift_180_lon\")\n",
    "    \n",
    "    try: \n",
    "        if not np.nanmin(zwda['longitude']) < -150: \n",
    "            zwda['longitude'] = (zwda['longitude'] + 180) % 360 - 180\n",
    "            addtxt=str(datetime.datetime.now())+' shift_180_lon to get longitude from -180 to 180'\n",
    "            try: zwda.attrs['history'] =  addtxt + ' ; '+zwda.attrs['history']\n",
    "            except: zwda.attrs['history'] =  addtxt             \n",
    "        #\n",
    "    except: print('WARNING! longitude likely not shifted')\n",
    "    return zwda\n",
    "#\n",
    "\n",
    "def rename_vars_dims_coords(ds, rename_dict, verbose=False):\n",
    "    \"\"\"\n",
    "    Renames variables, dimensions, and coordinates in an xarray Dataset according to the provided rename dictionary.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    ds : xr.Dataset\n",
    "        The xarray Dataset to be renamed.\n",
    "    rename_dict : Dict[str, str]\n",
    "        Dictionary containing the variable, dimension, or coordinate names to be renamed. \n",
    "        The keys represent the original names, and the values represent the new names.\n",
    "    verbose : bool, optional\n",
    "        If True, prints the function name at the start and end of execution (default is False).\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    xr.Dataset\n",
    "        A new xarray Dataset with variables, dimensions, and coordinates renamed according to the rename dictionary.\n",
    "    \n",
    "    Example:\n",
    "    --------\n",
    "    import xarray as xr\n",
    "    data = {'temp': ([], [0]), 'sali': ([], [1])}\n",
    "    coords = {'time': [0]}\n",
    "    ds = xr.Dataset(data, coords)\n",
    "    renamed_ds = rename_vars_dims_coords(ds, {'temp': 'temperature', 'sali': 'salinity'})\n",
    "\n",
    "    Dependencies:\n",
    "    -------------\n",
    "    xarray\n",
    "    \"\"\"\n",
    "    if verbose: print('func: rename_vars_dims_coords')\n",
    "    for old_name, new_name in rename_dict.items():\n",
    "        if (old_name in ds.variables) | (old_name in ds.dims) | (old_name in ds.coords): \n",
    "            ds = ds.rename({old_name: new_name})\n",
    "        #\n",
    "    if verbose: print('endfunc')\n",
    "    return ds\n",
    "#\n",
    "\n",
    "def split_coords_dimensions(ds, verbose=False):\n",
    "    \"\"\"\n",
    "    Splits the latitude, longitude, and depth dimensions and coordinates of an xarray dataset into separate variables,\n",
    "    updates their names, and assigns them back to the dataset.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    ds : xr.Dataset\n",
    "        The xarray Dataset to be updated.\n",
    "    verbose : bool, optional\n",
    "        If True, prints the function name at the start and end of execution (default is False).\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    xr.Dataset\n",
    "        A new xarray Dataset with the latitude, longitude, and depth dimensions and coordinates split into separate variables\n",
    "        and reassigned to the original dataset.\n",
    "    \n",
    "    Example:\n",
    "    --------\n",
    "    import xarray as xr\n",
    "    data = {'temp': ([0, 1, 2], [0, 1]), 'sali': ([0, 1, 2], [0, 1])}\n",
    "    coords = {'latitude': [0, 1, 2], 'longitude': [0, 1], 'depth': [0, 1, 2]}\n",
    "    ds = xr.Dataset(data, coords)\n",
    "    updated_ds = split_coords_dimensions(ds)\n",
    "\n",
    "    Dependencies:\n",
    "    -------------\n",
    "    xarray\n",
    "    \"\"\"\n",
    "    if verbose: print('func: split_coords_dimensions')\n",
    "    new_coords = {}\n",
    "    new_coords2 = {}\n",
    "    new_dims = {}\n",
    "    dim_name_dict = dict(latitude='j', longitude='i', depth='k')\n",
    "    dimschanged = []\n",
    "    for name, coord in ds.coords.items():\n",
    "        if name in ds.dims and name in [\"latitude\", \"longitude\", \"depth\"]:\n",
    "            new_coords[name + \"_coord\"] = coord\n",
    "            new_dims[name] = dim_name_dict[name]\n",
    "            new_coords2[name + \"_coord\"] = name\n",
    "            dimschanged.append(name)\n",
    "    if verbose: print('endfunc')\n",
    "    for name in ['k', 'j', 'i']: \n",
    "        if name in ds.coords: dimschanged.append(name)\n",
    "    #\n",
    "    return ds.assign_coords(new_coords).rename_dims(new_dims).drop_vars(dimschanged).rename(new_coords2)\n",
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad6d1fa-9081-41d8-84dd-7b74dd7d78d2",
   "metadata": {},
   "source": [
    "## Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31bdc511-ff83-422c-9eeb-bae08f2c1c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_esgf_dataset_filepaths(variable, sourceID, experimentID, \n",
    "                               freq='mon', grid='g*', version='latest', \n",
    "                               variant='r1i1p1f1',\n",
    "                               mipera = 'CMIP6', diresgf='/mnt/reef-ns1002k-esgf/', verbose=False, **kwargs): \n",
    "    \"\"\"\n",
    "    Returns the filepaths of the remote netCDF files corresponding to the specified dataset of the Earth System\n",
    "    Grid Federation (ESGF) data portal on NIRD.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    variable : str\n",
    "        Variable to search for on ESGF data portal.\n",
    "    sourceID : str\n",
    "        Name of the data source on the ESGF data portal.\n",
    "    experimentID : str\n",
    "        Name of the experiment on the ESGF data portal.\n",
    "    freq : str, optional\n",
    "        Frequency of the data (default is 'mon').\n",
    "    grid : str, optional\n",
    "        Type of grid (default is 'g*').\n",
    "    version : str, optional\n",
    "        Version of the data being queried (default is 'latest').\n",
    "    variant : str, optional\n",
    "        Label for the variant of the data being queried (default is 'r1i1p1f1').\n",
    "    mipera : str, optional\n",
    "        Name of the CMIP era being queried (default is 'CMIP6').\n",
    "    diresgf : str, optional\n",
    "        Absolute path to the directory where the data is stored (default is '/mnt/reef-ns1002k-esgf/').\n",
    "    verbose : bool, optional\n",
    "        If True, prints the function name at the start and end of execution (default is False).\n",
    "    **kwargs : dict, optional\n",
    "        Other key-value arguments to be passed in the function.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    List[str]\n",
    "        A list of filepaths corresponding to the specified dataset on the ESGF data portal.\n",
    "\n",
    "    Example:\n",
    "    --------\n",
    "    fp_list = get_esgf_dataset_filepaths('tas', 'CanESM5', 'historical', freq='mon')\n",
    "\n",
    "    Dependencies:\n",
    "    -------------\n",
    "    glob, sys\n",
    "    \"\"\"\n",
    "    import glob, sys\n",
    "    \n",
    "    if verbose: print('func: get_esgf_dataset_filepaths')\n",
    "    \n",
    "    if experimentID in ['1pctCO2', 'piControl', 'historical', 'abrupt-4xCO2']: zwActivity='CMIP'\n",
    "    elif experimentID in ['ssp126', 'ssp245', 'ssp585']: zwActivity='ScenarioMIP'\n",
    "    else: sys.exit('Check experimentID, case not implemented')\n",
    "    \n",
    "    if sourceID in ['CESM2', 'CESM2-WACCM']: zwInstitutionID = 'NCAR'\n",
    "    elif sourceID in ['ACCESS-ESM1-5']: zwInstitutionID = 'CSIRO'\n",
    "    elif sourceID in ['CNRM-ESM2-1']: zwInstitutionID = 'CNRM-CERFACS'\n",
    "    elif sourceID in ['CanESM5', 'CanESM5-CanOE']: zwInstitutionID = 'CCCma'\n",
    "    elif sourceID in ['UKESM1-0-LL']: zwInstitutionID = 'NIMS-KMA'\n",
    "    elif sourceID in ['GFDL-CM4', 'GFDL-ESM4']: zwInstitutionID = 'NOAA-GFDL'\n",
    "    elif sourceID in ['IPSL-CM6A-LR', 'IPSL-CM6A-LR-INCA']: zwInstitutionID = 'IPSL'\n",
    "    elif sourceID in ['MIROC-ES2L']: zwInstitutionID = 'MIROC'\n",
    "    elif sourceID in ['MPI-ESM1-2-LR', 'ICON-ESM-LR']: zwInstitutionID = 'MPI-M'\n",
    "    elif sourceID in ['NorESM2-LM']: zwInstitutionID = 'NCC'\n",
    "    else: sys.exit('Check sourceID, case not implemented')\n",
    "    \n",
    "    ocean_list = ['fgco2', 'intpp', 'o2', 'thetao', 'so', 'agessc', 'po4', 'no3']\n",
    "    if variable in ocean_list: zwTableID = 'O'+freq\n",
    "    elif variable in ['areacello']: zwTableID='Ofx'\n",
    "    elif variable in ['psl']: zwTableID='A'+freq\n",
    "    else: sys.exit('!!! WARNING !!! Check variable, case not implemented')\n",
    "        \n",
    "    zwdname = diresgf + mipera +'/'+ zwActivity +'/'+ \\\n",
    "        zwInstitutionID +'/'+ sourceID +'/'+ \\\n",
    "        experimentID  +'/'+ variant +'/'+ zwTableID +'/'+ \\\n",
    "        variable+'/'+ grid +'/'+ version +'/'\n",
    "    zwfname = variable +'_'+ zwTableID +'_'+ sourceID +'_'+ \\\n",
    "        experimentID +'_'+ variant +'_'+ grid +'*.nc' \n",
    "\n",
    "    if verbose: print('endfunc')\n",
    "    return glob.glob(zwdname + zwfname)\n",
    "#\n",
    "def nan_helper(y):\n",
    "    \"\"\"Helper to handle indices and logical indices of NaNs.\n",
    "\n",
    "    Input:\n",
    "        - y, 1d numpy array with possible NaNs\n",
    "    Output:\n",
    "        - nans, logical indices of NaNs\n",
    "        - index, a function, with signature indices= index(logical_indices),\n",
    "          to convert logical indices of NaNs to 'equivalent' indices\n",
    "    Example:\n",
    "        >>> # linear interpolation of NaNs\n",
    "        >>> nans, x= nan_helper(y)\n",
    "        >>> y[nans]= np.interp(x(nans), x(~nans), y[~nans])\n",
    "        nb: y[~nans] values of y that are not nans\n",
    "            x(~nans) indexes of y that are not nans\n",
    "    \"\"\"\n",
    "\n",
    "    return np.isnan(y), lambda z: z.nonzero()[0]\n",
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534741e5-b1be-4afb-a630-c5ede40b2b1e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## O2SAT and AOU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68a125d6-18cf-4ad0-af2d-2bc4793f453a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_o2sat_garcia(temp, saln, verbose=False):\n",
    "    \"\"\"\n",
    "    Calculates the dissolved oxygen concentration at saturation using the Garcia and Gordon (1992) equation.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    temp : xr.DataArray\n",
    "        DataArray containing the temperature values in degrees Celsius.\n",
    "    saln : xr.DataArray\n",
    "        DataArray containing the salinity values in practical salinity units.\n",
    "    verbose : bool\n",
    "        Print verbose output if True.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    xr.DataArray\n",
    "        DataArray containing the dissolved oxygen concentration at saturation in mol/m3.\n",
    "\n",
    "    Example:\n",
    "    --------\n",
    "    o2sat_data = get_o2sat_garcia(temp_data, sal_data)\n",
    "\n",
    "    Dependencies:\n",
    "    -------------\n",
    "    numpy\n",
    "    \"\"\"\n",
    "    \n",
    "    import numpy as np\n",
    "    \n",
    "    if verbose: print('func: get_o2sat_garcia')\n",
    "    # Garcia, H. E., & Gordon, L. I. (1993). Erratum: Oxygen solubility in seawater: better fitting equations. Limnology and Oceanography, 38, 656.\n",
    "    # Garcia, H. E., & Gordon, L. I. (1992). Oxygen solubility in seawater: Better fitting equations. Limnology and Oceanography, 37(6), 1307–1312. https://doi.org/10.4319/lo.1992.37.6.1307\n",
    "\n",
    "    #micromol/kg\n",
    "    A0=5.80818\n",
    "    A1=3.20684\n",
    "    A2=4.11890\n",
    "    A3=4.93845\n",
    "    A4=1.01567\n",
    "    A5=1.41575\n",
    "    B0=-7.01211e-3\n",
    "    B1=-7.25958e-3\n",
    "    B2=-7.93334e-3\n",
    "    B3=-5.54491e-3\n",
    "    C0=-1.32412e-7\n",
    "    \n",
    "    Ts = np.log((298.15-temp)/(273.15+temp))\n",
    "    OXY_nor = A0 + A1*Ts + A2*Ts**2 + A3*Ts**2 + A3*Ts**3 + A4*Ts**4 + A5*Ts**5 + saln*(B0 + B1*Ts + B2*Ts**2 + B3*Ts**3) + C0*saln**2\n",
    "    o2sat = np.exp(OXY_nor)*1.024e-3 # micromol/kg=> mol/m3\n",
    "        \n",
    "    o2sat.attrs['units']='mol m-3'\n",
    "    o2sat.attrs['longname']='Dissolved Oxygen Concentration at Saturation'\n",
    "    o2sat.attrs['description']='Dissolved Oxygen Concentration at Saturation computed following Garcia, H. E., & Gordon, L. I. (1993). \\\n",
    "    Erratum: Oxygen solubility in seawater: better fitting equations. Limnology and Oceanography, 38, 656. See also Garcia, H. E., & \\\n",
    "    Gordon, L. I. (1992). Oxygen solubility in seawater: Better fitting equations. Limnology and Oceanography, 37(6), 1307–1312.\\\n",
    "    Computed from temperature and salinity.'\n",
    "    o2sat = o2sat.rename('o2sat')\n",
    "    if verbose: print('endfunc')\n",
    "    \n",
    "    return o2sat #mol O2/m3\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d1ce29-260a-4287-a717-b9b99c05f45b",
   "metadata": {},
   "source": [
    "# Compute AOU for SSP585"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9096b9db-2c18-4a18-8e1e-7755d3f3dd9d",
   "metadata": {},
   "source": [
    "## Check data avaibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b87cc84-e878-4834-bc82-18134dfc2178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-22 10:56:26.959818\n",
      "# Compute AOU for SSP585\n",
      "THETAO, GOOD\n",
      "2015 to 2100, 86.0 years (1032 months)\n",
      "------------\n",
      "SO, GOOD\n",
      "2015 to 2100, 86.0 years (1032 months)\n",
      "------------\n",
      "O2, GOOD\n",
      "2015 to 2100, 86.0 years (1032 months)\n",
      "------------\n",
      "peak memory: 619.36 MiB, increment: 410.98 MiB\n",
      "CPU times: user 1.34 s, sys: 961 ms, total: 2.3 s\n",
      "Wall time: 9.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit -c\n",
    "print(datetime.datetime.now())\n",
    "print('# Compute AOU for SSP585')\n",
    "print('## Check data avaibility')\n",
    "\n",
    "simu = 'ssp585'\n",
    "esm  = 'NorESM2-LM'\n",
    "diresgf = '/mnt/reef-ns1002k-ns9034k/'\n",
    "version = 'v20191108'\n",
    "variant = 'r1i1p1f1'\n",
    "grid = 'gr'\n",
    "\n",
    "var_list = ['thetao', 'so', 'o2']\n",
    "for var in var_list: \n",
    "    fname_list = get_esgf_dataset_filepaths(var, esm, simu, \n",
    "                                            diresgf=diresgf, version=version, \n",
    "                                            variant=variant, grid=grid)\n",
    "    zwds = xr.open_mfdataset(fname_list, **kwopenmfds)\n",
    "    ymin = int(np.min(zwds['time.year']))\n",
    "    ymax = int(np.max(zwds['time.year']))\n",
    "    tstep = zwds[var].shape[0]\n",
    "    good = tstep/12 == ymax-ymin+1\n",
    "    if good: \n",
    "        print(f'{var.upper()}, GOOD')\n",
    "        print(f'{ymin} to {ymax}, {tstep/12} years ({tstep} months)')\n",
    "        print('------------')\n",
    "    else:\n",
    "        print('Years missing')\n",
    "        for fname in fname_list: print(fname)\n",
    "    #\n",
    "#  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4295deb9-c1f8-4e94-9e8c-fd5181ced43c",
   "metadata": {},
   "source": [
    "## Compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6683ec3b-ce0d-4e68-a3c2-ffbf0aab377d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-22 11:48:32.109096\n",
      "# Compute AOU for SSP585\n",
      "## Compute\n",
      "Done\n",
      "peak memory: 5108.88 MiB, increment: 4546.36 MiB\n",
      "CPU times: user 15min 32s, sys: 2min 33s, total: 18min 6s\n",
      "Wall time: 18min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit -c\n",
    "print(datetime.datetime.now())\n",
    "print('# Compute AOU for SSP585')\n",
    "print('## Compute')\n",
    "\n",
    "\n",
    "simu = 'ssp585'\n",
    "esm  = 'NorESM2-LM'\n",
    "diresgf = '/mnt/reef-ns1002k-ns9034k/'\n",
    "version = 'v20191108'\n",
    "variant = 'r1i1p1f1'\n",
    "grid = 'gr'\n",
    "\n",
    "year_list = ['%04d' %yyy for yyy in np.arange(2015, 2099.5)]\n",
    "\n",
    "# Load temperature\n",
    "var = 'thetao'\n",
    "fname_list = get_esgf_dataset_filepaths(var, esm, simu, \n",
    "                                        diresgf=diresgf, version=version, \n",
    "                                        variant=variant, grid=grid)\n",
    "zwds = xr.open_mfdataset(fname_list, **kwopenmfds)\n",
    "zwds2 = zwds[var].to_dataset()\n",
    "zwds2 = rename_vars_dims_coords(zwds2, rename_dict)\n",
    "zwds2 = split_coords_dimensions(zwds2)\n",
    "zwds_temp = shift_180_lon(zwds2)\n",
    "\n",
    "# Load salinity\n",
    "var = 'so'\n",
    "fname_list = get_esgf_dataset_filepaths(var, esm, simu, \n",
    "                                        diresgf=diresgf, version=version, \n",
    "                                        variant=variant, grid=grid)\n",
    "zwds = xr.open_mfdataset(fname_list, **kwopenmfds)\n",
    "zwds2 = zwds[var].to_dataset()\n",
    "zwds2 = rename_vars_dims_coords(zwds2, rename_dict)\n",
    "zwds2 = split_coords_dimensions(zwds2)\n",
    "zwds_sali = shift_180_lon(zwds2)\n",
    "\n",
    "# Load oxygen\n",
    "var = 'o2'\n",
    "fname_list = get_esgf_dataset_filepaths(var, esm, simu, \n",
    "                                        diresgf=diresgf, version=version, \n",
    "                                        variant=variant, grid=grid)\n",
    "zwds = xr.open_mfdataset(fname_list, **kwopenmfds)\n",
    "zwds2 = zwds[var].to_dataset()\n",
    "zwds2 = rename_vars_dims_coords(zwds2, rename_dict)\n",
    "zwds2 = split_coords_dimensions(zwds2)\n",
    "zwds_oxyg = shift_180_lon(zwds2)\n",
    "\n",
    "# save for later\n",
    "zwds_attrs=zwds.attrs\n",
    "\n",
    "del zwds, zwds2\n",
    "gc.collect()\n",
    "\n",
    "# Loop on years\n",
    "for year in year_list: \n",
    "\n",
    "    temp = zwds_temp.sel(time=year)['thetao'].load()\n",
    "    sali = zwds_sali.sel(time=year)['so'].load()\n",
    "    oxyg = zwds_oxyg.sel(time=year)['o2'].load()\n",
    "\n",
    "    # Compute o2sat\n",
    "    o2sat = get_o2sat_garcia(temp, sali, verbose=False).compute()\n",
    "\n",
    "    # Clean\n",
    "    del sali, temp\n",
    "    gc.collect()\n",
    "\n",
    "    # Compute aou\n",
    "    aou = xr.zeros_like(o2sat)\n",
    "    aou.values = o2sat.values - oxyg.values\n",
    "    aou.attrs={}\n",
    "    aou.attrs['units']='mol m-3'\n",
    "    aou.attrs['long_name']='Apparent Oxygen Utilization'\n",
    "    aou.attrs['description']='AOU computed as O2sat - O2 with O2sat computed following Garcia, H. E., & \\\n",
    "    Gordon, L. I. (1992). Oxygen solubility in seawater: Better fitting equations. Limnology and Oceanography, 37(6), 1307–1312.'\n",
    "    aou = aou.rename('aou')\n",
    "\n",
    "    # Clean\n",
    "    del oxyg\n",
    "    gc.collect()\n",
    "\n",
    "    # Temporal mean\n",
    "    o2sat_tavg = o2sat.groupby('time.year').mean(dim='time')\n",
    "    aou_tavg = aou.groupby('time.year').mean(dim='time')\n",
    "\n",
    "    # Clean\n",
    "    del o2sat, aou\n",
    "    gc.collect()\n",
    "\n",
    "    # create dataset\n",
    "    o2sat_ds = o2sat_tavg.to_dataset() \n",
    "    o2sat_ds.attrs = zwds_attrs\n",
    "    aou_ds = aou_tavg.to_dataset() \n",
    "    aou_ds.attrs = zwds_attrs\n",
    "\n",
    "    # Save in netcdf\n",
    "    #---------------    \n",
    "    # print('Save in netcdf...')\n",
    "    ncname = netcdfdir+esm+'_'+simu+'_o2sat_'+year+'.nc'\n",
    "    o2sat_ds.to_netcdf(ncname)\n",
    "    # print('File saved: %s'%ncname)\n",
    "    #---------------    \n",
    "    # print('Save in netcdf...')\n",
    "    ncname = netcdfdir+esm+'_'+simu+'_aou_'+year+'.nc'\n",
    "    aou_ds.to_netcdf(ncname)\n",
    "    # print('File saved: %s'%ncname)\n",
    "#\n",
    "print('Done')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521f4862-4b51-4b3a-b838-c703ff6fe65f",
   "metadata": {},
   "source": [
    "# Compute AOU for historical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cda597-8a8b-4845-ab3c-2f1807425253",
   "metadata": {},
   "source": [
    "## Check data avaibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bb4e9fb-ef2c-430c-8552-0ad7e271db0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-22 11:38:45.026671\n",
      "# Compute AOU for hitsorical\n",
      "## Check data avaibility\n",
      "THETAO, GOOD\n",
      "1850 to 2014, 165.0 years (1980 months)\n",
      "------------\n",
      "SO, GOOD\n",
      "1850 to 2014, 165.0 years (1980 months)\n",
      "------------\n",
      "O2, GOOD\n",
      "1850 to 2014, 165.0 years (1980 months)\n",
      "------------\n",
      "peak memory: 904.45 MiB, increment: 443.49 MiB\n",
      "CPU times: user 1.52 s, sys: 453 ms, total: 1.98 s\n",
      "Wall time: 13.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit -c\n",
    "print(datetime.datetime.now())\n",
    "print('# Compute AOU for hitsorical')\n",
    "print('## Check data avaibility')\n",
    "\n",
    "simu='historical'\n",
    "esm  = 'NorESM2-LM'\n",
    "diresgf = '/mnt/reef-ns1002k-ns9034k/'\n",
    "version = 'v20190815'\n",
    "variant = 'r1i1p1f1'\n",
    "grid = 'gr'\n",
    "\n",
    "var_list = ['thetao', 'so', 'o2']\n",
    "for var in var_list: \n",
    "    fname_list = get_esgf_dataset_filepaths(var, esm, simu, \n",
    "                                            diresgf=diresgf, version=version, \n",
    "                                            variant=variant, grid=grid)\n",
    "    zwds = xr.open_mfdataset(fname_list, **kwopenmfds)\n",
    "    ymin = int(np.min(zwds['time.year']))\n",
    "    ymax = int(np.max(zwds['time.year']))\n",
    "    tstep = zwds[var].shape[0]\n",
    "    good = tstep/12 == ymax-ymin+1\n",
    "    if good: \n",
    "        print(f'{var.upper()}, GOOD')\n",
    "        print(f'{ymin} to {ymax}, {tstep/12} years ({tstep} months)')\n",
    "        print('------------')\n",
    "    else:\n",
    "        print('Years missing')\n",
    "        for fname in fname_list: print(fname)\n",
    "    #\n",
    "#  \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ea3b56-0b21-4ebe-b1eb-31cd3f86e72c",
   "metadata": {},
   "source": [
    "## Compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d33b43b0-e68e-4c7a-935a-d1c7571dda73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-22 12:07:14.437671\n",
      "# Compute AOU for historical\n",
      "## Compute\n",
      "Done\n",
      "peak memory: 6779.99 MiB, increment: 5238.19 MiB\n",
      "CPU times: user 30min 28s, sys: 4min 52s, total: 35min 20s\n",
      "Wall time: 36min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit -c\n",
    "print(datetime.datetime.now())\n",
    "print('# Compute AOU for historical')\n",
    "print('## Compute')\n",
    "\n",
    "simu='historical'\n",
    "esm  = 'NorESM2-LM'\n",
    "diresgf = '/mnt/reef-ns1002k-ns9034k/'\n",
    "version = 'v20190815'\n",
    "variant = 'r1i1p1f1'\n",
    "grid = 'gr'\n",
    "\n",
    "year_list = ['%04d' %yyy for yyy in np.arange(1850, 2014.5)]\n",
    "\n",
    "# Load temperature\n",
    "var = 'thetao'\n",
    "fname_list = get_esgf_dataset_filepaths(var, esm, simu, \n",
    "                                        diresgf=diresgf, version=version, \n",
    "                                        variant=variant, grid=grid)\n",
    "zwds = xr.open_mfdataset(fname_list, **kwopenmfds)\n",
    "zwds2 = zwds[var].to_dataset()\n",
    "zwds2 = rename_vars_dims_coords(zwds2, rename_dict)\n",
    "zwds2 = split_coords_dimensions(zwds2)\n",
    "zwds_temp = shift_180_lon(zwds2)\n",
    "\n",
    "# Load salinity\n",
    "var = 'so'\n",
    "fname_list = get_esgf_dataset_filepaths(var, esm, simu, \n",
    "                                        diresgf=diresgf, version=version, \n",
    "                                        variant=variant, grid=grid)\n",
    "zwds = xr.open_mfdataset(fname_list, **kwopenmfds)\n",
    "zwds2 = zwds[var].to_dataset()\n",
    "zwds2 = rename_vars_dims_coords(zwds2, rename_dict)\n",
    "zwds2 = split_coords_dimensions(zwds2)\n",
    "zwds_sali = shift_180_lon(zwds2)\n",
    "\n",
    "# Load oxygen\n",
    "var = 'o2'\n",
    "fname_list = get_esgf_dataset_filepaths(var, esm, simu, \n",
    "                                        diresgf=diresgf, version=version, \n",
    "                                        variant=variant, grid=grid)\n",
    "zwds = xr.open_mfdataset(fname_list, **kwopenmfds)\n",
    "zwds2 = zwds[var].to_dataset()\n",
    "zwds2 = rename_vars_dims_coords(zwds2, rename_dict)\n",
    "zwds2 = split_coords_dimensions(zwds2)\n",
    "zwds_oxyg = shift_180_lon(zwds2)\n",
    "\n",
    "# save for later\n",
    "zwds_attrs=zwds.attrs\n",
    "\n",
    "del zwds, zwds2\n",
    "gc.collect()\n",
    "\n",
    "# Loop on years\n",
    "for year in year_list: \n",
    "\n",
    "    temp = zwds_temp.sel(time=year)['thetao'].load()\n",
    "    sali = zwds_sali.sel(time=year)['so'].load()\n",
    "    oxyg = zwds_oxyg.sel(time=year)['o2'].load()\n",
    "\n",
    "    # Compute o2sat\n",
    "    o2sat = get_o2sat_garcia(temp, sali, verbose=False).compute()\n",
    "\n",
    "    # Clean\n",
    "    del sali, temp\n",
    "    gc.collect()\n",
    "\n",
    "    # Compute aou\n",
    "    aou = xr.zeros_like(o2sat)\n",
    "    aou.values = o2sat.values - oxyg.values\n",
    "    aou.attrs={}\n",
    "    aou.attrs['units']='mol m-3'\n",
    "    aou.attrs['long_name']='Apparent Oxygen Utilization'\n",
    "    aou.attrs['description']='AOU computed as O2sat - O2 with O2sat computed following Garcia, H. E., & \\\n",
    "    Gordon, L. I. (1992). Oxygen solubility in seawater: Better fitting equations. Limnology and Oceanography, 37(6), 1307–1312.'\n",
    "    aou = aou.rename('aou')\n",
    "\n",
    "    # Clean\n",
    "    del oxyg\n",
    "    gc.collect()\n",
    "\n",
    "    # Temporal mean\n",
    "    o2sat_tavg = o2sat.groupby('time.year').mean(dim='time')\n",
    "    aou_tavg = aou.groupby('time.year').mean(dim='time')\n",
    "\n",
    "    # Clean\n",
    "    del o2sat, aou\n",
    "    gc.collect()\n",
    "\n",
    "    # create dataset\n",
    "    o2sat_ds = o2sat_tavg.to_dataset() \n",
    "    o2sat_ds.attrs = zwds_attrs\n",
    "    aou_ds = aou_tavg.to_dataset() \n",
    "    aou_ds.attrs = zwds_attrs\n",
    "\n",
    "    # Save in netcdf\n",
    "    #---------------    \n",
    "    # print('Save in netcdf...')\n",
    "    ncname = netcdfdir+esm+'_'+simu+'_o2sat_'+year+'.nc'\n",
    "    o2sat_ds.to_netcdf(ncname)\n",
    "    # print('File saved: %s'%ncname)\n",
    "    #---------------    \n",
    "    # print('Save in netcdf...')\n",
    "    ncname = netcdfdir+esm+'_'+simu+'_aou_'+year+'.nc'\n",
    "    aou_ds.to_netcdf(ncname)\n",
    "    # print('File saved: %s'%ncname)\n",
    "#\n",
    "print('Done')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b08ce8-7510-4db6-94be-667f48cec107",
   "metadata": {},
   "source": [
    "# Compute AOU for piControl with specific years depending on models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e811d48-fb02-4da4-84c9-6ed45a3e5946",
   "metadata": {},
   "source": [
    "## def shorten_fname_list(fname_list, startyear, endyear):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2627b4ca-6af5-47c8-8015-94935707bdf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def shorten_fname_list(fname_list, startyear, endyear):\n",
    "    fname_list.sort()\n",
    "    new_fname_list = []\n",
    "    for fname in fname_list: \n",
    "        year1_of_fname = int(fname.split('/')[-1].split('_')[-1].split('-')[0][:4])\n",
    "        year2_of_fname = int(fname.split('/')[-1].split('_')[-1].split('-')[1][:4])\n",
    "        startyear_in_between = ((startyear>=year1_of_fname) & (startyear<=year2_of_fname))\n",
    "        endyear_in_between   = ((endyear>=year1_of_fname) & (endyear<=year2_of_fname))\n",
    "        year1_in_between = ((year1_of_fname>=startyear) & (year1_of_fname<=endyear))\n",
    "        year2_in_between = ((year2_of_fname>=startyear) & (year2_of_fname<=endyear))\n",
    "        if startyear_in_between | endyear_in_between | year1_in_between | year2_in_between: \n",
    "            if not (fname in new_fname_list): \n",
    "                new_fname_list.append(fname)\n",
    "        #\n",
    "    #\n",
    "    if len(new_fname_list)==0: new_fname_list=fname_list\n",
    "    return new_fname_list\n",
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a8dbd1-7a7c-4241-9dba-5108a693e155",
   "metadata": {},
   "source": [
    "## Check data avaibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b018bfd6-033f-42df-890c-977a6b9371ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-22 16:36:10.777262\n",
      "# Compute AOU for piControl with specific years depending on models\n",
      "## Check data avaibility\n",
      "------------\n",
      "piControl targeted time period: 1600-1849\n",
      ">>> THETAO: GOOD, time period complete and match target\n",
      "1600 to 1850, 251.0 years (3012 months)\n",
      "------------\n",
      "piControl targeted time period: 1600-1849\n",
      ">>> SO: GOOD, time period complete and match target\n",
      "1600 to 1850, 251.0 years (3012 months)\n",
      "------------\n",
      "piControl targeted time period: 1600-1849\n",
      ">>> O2: GOOD, time period complete and match target\n",
      "1600 to 1850, 251.0 years (3012 months)\n",
      "------------\n",
      "Done\n",
      "peak memory: 701.09 MiB, increment: 517.32 MiB\n",
      "CPU times: user 2.75 s, sys: 1.42 s, total: 4.17 s\n",
      "Wall time: 22.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit -c\n",
    "print(datetime.datetime.now())\n",
    "print('# Compute AOU for piControl with specific years depending on models')\n",
    "print('## Check data avaibility')\n",
    "\n",
    "simu='piControl'\n",
    "esm  = 'NorESM2-LM'\n",
    "diresgf = '/mnt/reef-ns1002k-ns9034k/'\n",
    "version = 'v20210118'\n",
    "variant = 'r1i1p1f1'\n",
    "grid = 'gr'\n",
    "\n",
    "refyear_dict = {\n",
    "    'MPI-ESM1-2-LR': 1850,\n",
    "    'ACCESS-ESM1-5':  161,\n",
    "    'IPSL-CM6A-LR' : 1910,\n",
    "    'CanESM5'      : 5201,\n",
    "    'MIROC-ES2L'   : 1850,\n",
    "    'NorESM2-LM'   : 1600\n",
    "}\n",
    "\n",
    "import time\n",
    "\n",
    "# Pause execution for 10 seconds\n",
    "#time.sleep(10)\n",
    "\n",
    "var_list = ['thetao', 'so', 'o2']\n",
    "for var in var_list: \n",
    "\n",
    "    print('------------')\n",
    "    startyear, endyear = refyear_dict[esm], refyear_dict[esm]+165+84\n",
    "    print('piControl targeted time period: %04d-%04d'%(startyear, endyear))\n",
    "\n",
    "    fname_list = get_esgf_dataset_filepaths(var, esm, simu, \n",
    "                                            diresgf=diresgf, version=version, \n",
    "                                            variant=variant, grid=grid)\n",
    "    new_fname_list = shorten_fname_list(fname_list, startyear, endyear)\n",
    "    zwds = xr.open_mfdataset(new_fname_list, **kwopenmfds)\n",
    "    ymin = int(np.min(zwds['time.year']))\n",
    "    ymax = int(np.max(zwds['time.year']))\n",
    "    tstep = zwds[var].shape[0]\n",
    "    good1 = tstep/12 == ymax-ymin+1\n",
    "    good2 = (startyear>=ymin) & (endyear<=ymax)\n",
    "    if good1 & good2: \n",
    "        print(f'>>> {var.upper()}: GOOD, time period complete and match target')\n",
    "        print(f'{ymin} to {ymax}, {tstep/12} years ({tstep} months)')\n",
    "    elif good1 and (not good2): \n",
    "        print(f'!!! {var.upper()}: time period complete BUT do not match target')\n",
    "        print(f'{ymin} to {ymax}, {tstep/12} years ({tstep} months), file list:')\n",
    "        for fname in fname_list: print(fname)\n",
    "    else: \n",
    "        print(f'!!! {var.upper()}: some years are missing. Here is the file list: ')\n",
    "        for fname in fname_list: print(fname)\n",
    "    #\n",
    "#  \n",
    "print('------------')\n",
    "print('Done')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c361c43-84d8-42db-b760-61ec3a96f521",
   "metadata": {},
   "source": [
    "## Compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef92acdc-257a-4f48-bd36-a5c3b4266167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-22 16:37:50.273700\n",
      "# Compute AOU for piControl with specific years depending on models\n",
      "## Compute\n",
      "Done\n",
      "peak memory: 5097.25 MiB, increment: 4539.54 MiB\n",
      "CPU times: user 15min 16s, sys: 2min 27s, total: 17min 44s\n",
      "Wall time: 18min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit -c\n",
    "\n",
    "print(datetime.datetime.now())\n",
    "print('# Compute AOU for piControl with specific years depending on models')\n",
    "print('## Compute')\n",
    "\n",
    "\n",
    "simu='piControl'\n",
    "esm  = 'NorESM2-LM'\n",
    "diresgf = '/mnt/reef-ns1002k-ns9034k/'\n",
    "version = 'v20210118'\n",
    "variant = 'r1i1p1f1'\n",
    "grid = 'gr'\n",
    "\n",
    "refyear_dict = {\n",
    "    'MPI-ESM1-2-LR': 1850,\n",
    "    'ACCESS-ESM1-5':  161,\n",
    "    'IPSL-CM6A-LR' : 1910,\n",
    "    'CanESM5'      : 5201,\n",
    "    'MIROC-ES2L'   : 1850,\n",
    "    'NorESM2-LM'   : 1600\n",
    "}\n",
    "\n",
    "\n",
    "startyear, endyear = refyear_dict[esm]+165, refyear_dict[esm]+165+84\n",
    "\n",
    "# Load temperature\n",
    "var = 'thetao'\n",
    "fname_list = get_esgf_dataset_filepaths(var, esm, simu, \n",
    "                                            diresgf=diresgf, version=version, \n",
    "                                            variant=variant, grid=grid)\n",
    "new_fname_list = shorten_fname_list(fname_list, startyear, endyear)\n",
    "zwds = xr.open_mfdataset(new_fname_list, **kwopenmfds)\n",
    "zwds2 = zwds[var].to_dataset()\n",
    "zwds2 = rename_vars_dims_coords(zwds2, rename_dict)\n",
    "zwds2 = split_coords_dimensions(zwds2)\n",
    "zwds_temp = shift_180_lon(zwds2)\n",
    "\n",
    "# Load salinity\n",
    "var = 'so'\n",
    "fname_list = get_esgf_dataset_filepaths(var, esm, simu, \n",
    "                                            diresgf=diresgf, version=version, \n",
    "                                            variant=variant, grid=grid)\n",
    "new_fname_list = shorten_fname_list(fname_list, startyear, endyear)\n",
    "zwds = xr.open_mfdataset(new_fname_list, **kwopenmfds)\n",
    "zwds2 = zwds[var].to_dataset()\n",
    "zwds2 = rename_vars_dims_coords(zwds2, rename_dict)\n",
    "zwds2 = split_coords_dimensions(zwds2)\n",
    "zwds_sali = shift_180_lon(zwds2)\n",
    "\n",
    "# Load oxygen\n",
    "var = 'o2'\n",
    "fname_list = get_esgf_dataset_filepaths(var, esm, simu, \n",
    "                                            diresgf=diresgf, version=version, \n",
    "                                            variant=variant, grid=grid)\n",
    "new_fname_list = shorten_fname_list(fname_list, startyear, endyear)\n",
    "zwds = xr.open_mfdataset(new_fname_list, **kwopenmfds)\n",
    "zwds2 = zwds[var].to_dataset()\n",
    "zwds2 = rename_vars_dims_coords(zwds2, rename_dict)\n",
    "zwds2 = split_coords_dimensions(zwds2)\n",
    "zwds_oxyg = shift_180_lon(zwds2)\n",
    "\n",
    "# save for later\n",
    "zwds_attrs=zwds.attrs\n",
    "year_list = ['%04d' %yyy for yyy in np.arange(startyear, endyear+.5)]\n",
    "\n",
    "del zwds, zwds2\n",
    "gc.collect()\n",
    "\n",
    "# Loop on years\n",
    "for year in year_list: \n",
    "\n",
    "    temp = zwds_temp.sel(time=year)['thetao'].load()\n",
    "    sali = zwds_sali.sel(time=year)['so'].load()\n",
    "    oxyg = zwds_oxyg.sel(time=year)['o2'].load()\n",
    "\n",
    "    # Compute o2sat\n",
    "    o2sat = get_o2sat_garcia(temp, sali, verbose=False).compute()\n",
    "\n",
    "    # Clean\n",
    "    del sali, temp\n",
    "    gc.collect()\n",
    "\n",
    "    # Compute aou\n",
    "    aou = xr.zeros_like(o2sat)\n",
    "    aou.values = o2sat.values - oxyg.values\n",
    "    aou.attrs={}\n",
    "    aou.attrs['units']='mol m-3'\n",
    "    aou.attrs['long_name']='Apparent Oxygen Utilization'\n",
    "    aou.attrs['description']='AOU computed as O2sat - O2 with O2sat computed following Garcia, H. E., & \\\n",
    "    Gordon, L. I. (1992). Oxygen solubility in seawater: Better fitting equations. Limnology and Oceanography, 37(6), 1307–1312.'\n",
    "    aou = aou.rename('aou')\n",
    "\n",
    "    # Clean\n",
    "    del oxyg\n",
    "    gc.collect()\n",
    "\n",
    "    # Temporal mean\n",
    "    o2sat_tavg = o2sat.groupby('time.year').mean(dim='time')\n",
    "    aou_tavg = aou.groupby('time.year').mean(dim='time')\n",
    "\n",
    "    # Clean\n",
    "    del o2sat, aou\n",
    "    gc.collect()\n",
    "\n",
    "    # create dataset\n",
    "    o2sat_ds = o2sat_tavg.to_dataset() \n",
    "    o2sat_ds.attrs = zwds_attrs\n",
    "    aou_ds = aou_tavg.to_dataset() \n",
    "    aou_ds.attrs = zwds_attrs\n",
    "\n",
    "    # Save in netcdf\n",
    "    #---------------    \n",
    "    # print('Save in netcdf...')\n",
    "    ncname = netcdfdir+esm+'_'+simu+'_o2sat_'+year+'.nc'\n",
    "    o2sat_ds.to_netcdf(ncname)\n",
    "    # print('File saved: %s'%ncname)\n",
    "    #---------------    \n",
    "    # print('Save in netcdf...')\n",
    "    ncname = netcdfdir+esm+'_'+simu+'_aou_'+year+'.nc'\n",
    "    aou_ds.to_netcdf(ncname)\n",
    "    # print('File saved: %s'%ncname)\n",
    "#\n",
    "print(f'Done')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0ee9a1-7282-4dee-b267-1e27883b8b78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
